---
title: "Natural Language Processing"
date: "2018-09-29T11:36:33+08:00"
draft: false
tags:
  - Demo
  - Typography
---

Here are some papers which every computer vision enthusiast should look into:
- Attention is all You Need ([link](https://arxiv.org/pdf/1706.03762.pdf))
- Adversarial Training Methods for Semi-Supervised Text Classification ([link](https://arxiv.org/pdf/1605.07725v3.pdf))
- DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter ([link](https://arxiv.org/pdf/1910.01108v4.pdf))
- Deep contextualized word representations ([link](https://arxiv.org/pdf/1802.05365v2.pdf))
- Incorporating BERT into Neural Machine Translation ([link](https://arxiv.org/pdf/2002.06823v1.pdf))
- Unsupervised Statistical Machine Translation ([link](https://arxiv.org/pdf/1809.01272v1.pdf))
- DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation ([link](https://www.aclweb.org/anthology/D19-1015.pdf))
- DialogueRNN: An Attentive RNN for Emotion Detection in Conversations ([link](https://arxiv.org/pdf/1811.00405v4.pdf))